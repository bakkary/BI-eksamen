{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97efdf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install plotly\n",
    "! pip install folium\n",
    "! pip install fuzzywuzzy\n",
    "! pip install python-Levenshtein\n",
    "! pip install pycountry-convert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8657e51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas for structuring the data\n",
    "import pandas as pd\n",
    "\n",
    "# import numpy for numerical analysis\n",
    "import numpy as np\n",
    "\n",
    "# import libs for diagrams inline with the text\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# other utilities\n",
    "from sklearn import datasets, preprocessing, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.io as pio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics as sm\n",
    "\n",
    "# for diagramming \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For serialization and deserialization of data from/to file\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa693206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the json file from your data folder into a data frame\n",
    "#df = pd.read_csv(r'C:\\Users\\chz\\Documents\\BI Exercise\\\\BI Exam\\global air pollution dataset.csv')\n",
    "df = pd.read_csv(r'C:\\Users\\chz\\Documents\\BI Exercise\\Datasæt\\global_air_pollution_dataset.csv')\n",
    "df2 = pd.read_csv(r\"C:\\Users\\chz\\Documents\\BI Exercise\\Datasæt\\2017_-_Cities_Community_Wide_Emissions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the 'Country' column in both DataFrames\n",
    "df['Country'] = df['Country'].str.title().str.strip()\n",
    "df2['Country'] = df2['Country'].str.title().str.strip()\n",
    "\n",
    "# Merging df and df2 based on 'Country' after standardization\n",
    "df_merged = pd.merge(df, df2, on='Country', how='outer')\n",
    "\n",
    "# Sampling 50 rows from the merged DataFrame to verify the operation\n",
    "# Note: Since the actual DataFrames are empty in this simulation, this step is for demonstration purposes.\n",
    "sampled_df_merged = df_merged.sample(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a3c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c8ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop(columns=['Gases included'], inplace=True)\n",
    "df_merged.drop(columns=['Comment'], inplace=True)\n",
    "df_merged.drop(columns=['Total Scope 1 Emissions (metric tonnes CO2e)'], inplace=True)\n",
    "df_merged.drop(columns=['Total Scope 2 Emissions (metric tonnes CO2e)'], inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert nulls/NaNs to 'False'\n",
    "df_merged['C40'] = df_merged['C40'].fillna('False')\n",
    "\n",
    "# Convert any cell that contains \"C40\" to 'True', assuming \"C40\" indicates a true condition\n",
    "# Adjust the condition as needed to match your data's specific representation of true\n",
    "df_merged['C40'] = df_merged['C40'].apply(lambda x: 'True' if 'C40' in str(x) else 'False')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4054ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the null values from the data frame\n",
    "df_merged = df_merged.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c3ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data frame for null values\n",
    "df_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2328ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af5469d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merged.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8382b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracting latitude and longitude from \"City Location\" and \"Country Location\" into new columns\n",
    "df_merged[['City Latitude', 'City Longitude']] = df_merged['City Location'].str.extract(r'\\(([^,]+), ([^)]+)\\)')\n",
    "df_merged[['Country Latitude', 'Country Longitude']] = df_merged['Country Location'].str.extract(r'\\(([^,]+), ([^)]+)\\)')\n",
    "\n",
    "# Displaying the first few rows to ensure the transformation was successful\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5b9a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the latitude and longitude columns from strings to floats\n",
    "df_merged['City Latitude'] = pd.to_numeric(df_merged['City Latitude'], errors='coerce')\n",
    "df_merged['City Longitude'] = pd.to_numeric(df_merged['City Longitude'], errors='coerce')\n",
    "df_merged['Country Latitude'] = pd.to_numeric(df_merged['Country Latitude'], errors='coerce')\n",
    "df_merged['Country Longitude'] = pd.to_numeric(df_merged['Country Longitude'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ec6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop(columns=['City Location'], inplace=True)\n",
    "df_merged.drop(columns=['Country Location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c658a0a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert 'C40' from strings \"True\"/\"False\" to actual booleans\n",
    "df_merged['C40'] = df_merged['C40'].map({'True': True, 'False': False})\n",
    "\n",
    "# Create two new columns: 'C40_True' and 'C40_False'\n",
    "df_merged['C40_True'] = df_merged['C40'].astype(int)  # This will convert True to 1 and False to 0\n",
    "df_merged['C40_False'] = (~df_merged['C40']).astype(int)  # This inverts the boolean and then converts to 0/1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58e5b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop(columns=['C40'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ec48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32c49b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba503efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761cee60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pycountry_convert as pc\n",
    "\n",
    "#applying continent to the dataset for future use of folium mapping\n",
    "def country_to_continent(country_name):\n",
    "    try:\n",
    "        country_alpha2 = pc.country_name_to_country_alpha2(country_name)\n",
    "        country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n",
    "        country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "        return country_continent_name\n",
    "    except:\n",
    "        return None  # For countries that don't match\n",
    "\n",
    "# Apply the conversion function to your DataFrame\n",
    "df['Continent'] = df['Country'].apply(country_to_continent)\n",
    "# Filter for other continents\n",
    "north_american_countries_df = df[df['Continent'] == 'North America']\n",
    "south_american_countries_df = df[df['Continent'] == 'South America']\n",
    "asian_countries_df = df[df['Continent'] == 'Asia']\n",
    "african_countries_df = df[df['Continent'] == 'Africa']\n",
    "oceania_countries_df = df[df['Continent'] == 'Oceania']\n",
    "Europe_df = df[df['Continent'] == 'Europe']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cb16d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c781c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to convert the data from float to int in order to use pandas to calculate the correlations\n",
    "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "\n",
    "df_cleaned = numeric_df.dropna()\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = df_cleaned.corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bcd297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing relationships between all numerical features\n",
    "sns.pairplot(df.select_dtypes(include=['float64', 'int64']))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec68ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('AQI Value')\n",
    "plt.ylabel('PM2.5 AQI Value')\n",
    "plt.scatter(df['AQI Value'], df['PM2.5 AQI Value'], color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8399c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['AQI Value'],  label='AQI Value', norm_hist=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['PM2.5 AQI Value'],  label='PM2.5 AQI Value', norm_hist=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c1f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the data by 'Country' and calculating the mean 'AQI Value' for each country\n",
    "country_aqi_means = df.groupby('Country')['AQI Value'].mean()\n",
    "\n",
    "# Sorting the countries by AQI value for better visualization\n",
    "country_aqi_means = country_aqi_means.sort_values()\n",
    "\n",
    "# Creating the bar chart\n",
    "plt.figure(figsize=(15, 25)) \n",
    "plt.barh(country_aqi_means.index, country_aqi_means.values, color='skyblue') # Horizontal bar chart\n",
    "plt.xlabel('Average AQI Value')\n",
    "plt.ylabel('Country')\n",
    "plt.title('Average AQI Value by Country')\n",
    "plt.tight_layout() # Adjusts subplot params so that the subplot(s) fits in to the figure area.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df2225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the data by 'Country' and calculating the mean 'PM2.5 AQI Value' for each country\n",
    "country_pm25_means = df.groupby('Country')['PM2.5 AQI Value'].mean()\n",
    "# Sorting the countries by PM2.5 AQI value for better visualization\n",
    "country_pm25_means = country_pm25_means.sort_values()\n",
    "# Creating the bar chart\n",
    "plt.figure(figsize=(15, 25))\n",
    "plt.barh(country_pm25_means.index, country_pm25_means.values, color='skyblue') # Horizontal bar chart\n",
    "plt.xlabel('Average PM2.5 AQI Value')\n",
    "plt.ylabel('Country')\n",
    "plt.title('Average PM2.5 AQI Value by Country')\n",
    "plt.tight_layout() # Adjusts subplot params so that the subplot(s) fits in to the figure area.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1beec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['AQI Value'].values.reshape(-1, 1)\n",
    "y = df['PM2.5 AQI Value'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all\n",
    "plt.ylabel('PM2.5 AQI Value')\n",
    "plt.xlabel('AQI Value')\n",
    "plt.scatter(X, y, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14117185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123, test_size=0.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6895792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape of the subsets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c3a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instance of Linear Regression model\n",
    "myreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da9438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit it to our data\n",
    "myreg.fit(X_train, y_train)\n",
    "myreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the calculated coefficients\n",
    "a = myreg.coef_\n",
    "b = myreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c9f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d703a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = myreg.predict(X_test)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad11cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e01d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the Linear Regression \n",
    "plt.title('Linear Regression')\n",
    "plt.scatter(X, y, color='green')\n",
    "plt.plot(X_train, a*X_train + b, color='blue')\n",
    "plt.plot(X_test, y_predicted, color='orange')\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('age')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d67d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = myreg.predict(X_test)\n",
    "\n",
    "# Calculating metrics\n",
    "print(\"R^2: \", r2_score(y_test, y_pred))\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be591e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a scatter plot of the 'AQI Value' and 'PM2.5 AQI Value' columns and color the points by the 'Country' column\n",
    "fig = px.scatter(df, x='AQI Value', y='PM2.5 AQI Value', color='Country', title='AQI Value vs PM2.5 AQI Value')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9940e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the data into 5 clusters using the KMeans algorithm\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(df[['AQI Value', 'PM2.5 AQI Value']])\n",
    "df['cluster'] = kmeans.predict(df[['AQI Value', 'PM2.5 AQI Value']])\n",
    "df.sample(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b38e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scatter plot of the 'AQI Value' and 'PM2.5 AQI Value' columns and color the points by the 'cluster' column\n",
    "fig = px.scatter(df, x='AQI Value', y='PM2.5 AQI Value', color='cluster', title='AQI Value vs PM2.5 AQI Value')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd2c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model and predict clusters\n",
    "kmeans = KMeans(n_clusters=5, random_state=42).fit(df_filtered[['AQI Value', 'PM2.5 AQI Value']])\n",
    "df_filtered['cluster'] = kmeans.labels_\n",
    "\n",
    "# Analyze centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(\"Centroids:\\n\", centroids)\n",
    "\n",
    "# Plotting clusters and centroids\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_filtered, x='AQI Value', y='PM2.5 AQI Value', hue='cluster', palette='viridis')\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], s=100, c='red', label='Centroids')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d392b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_data = df[['Country', 'Population']]\n",
    "\n",
    "# Grouping and aggregating population data by country\n",
    "population_by_country = population_data.groupby('Country')['Population'].sum().reset_index()\n",
    "\n",
    "# Creating a pivot table with 'Country' as index\n",
    "pivot_population = population_by_country.set_index('Country')\n",
    "\n",
    "# Creating the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(data=pivot_population, cmap='YlGnBu', annot=True, fmt=',.0f', linewidths=.5)\n",
    "plt.title('Population by Country')\n",
    "plt.xlabel('population')\n",
    "plt.ylabel('Country')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f35646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the 'Country Location' column into separate longitude and latitude columns\n",
    "df[['Latitude', 'Longitude']] = df['Country Location'].str.strip('()').str.split(', ', expand=True).astype(float)\n",
    "\n",
    "# Creating a 3D scatter plot\n",
    "scatter_plot = go.Scatter3d(\n",
    "    x=df['Longitude'],\n",
    "    y=df['Latitude'],\n",
    "    z=df['Population year'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color='blue',                # Set color to an array/list of desired values\n",
    "        opacity=0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "# Setting layout\n",
    "layout = go.Layout(\n",
    "    title='3D Population Map',\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='Country Longitude'),\n",
    "        yaxis=dict(title='Country Latitude'),\n",
    "        zaxis=dict(title='Population')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combining data and layout into a figure\n",
    "fig = go.Figure(data=[scatter_plot], layout=layout)\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4086d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import json\n",
    "\n",
    "# Load the GeoJSON data from a local file\n",
    "with open(r\"C:\\Users\\chz\\Documents\\BI Exercise\\Datasæt\\custom.geo.json\", 'r', encoding='utf-8') as f:\n",
    "    geojson_data = json.load(f)\n",
    "\n",
    "# Assuming 'df' is your DataFrame and already correctly set up\n",
    "m = folium.Map(location=[df['Country Latitude'].mean(), df['Country Longitude'].mean()], zoom_start=3)\n",
    "\n",
    "# Add markers for each data point\n",
    "for index, row in df.iterrows():\n",
    "    folium.Marker([row['Country Latitude'], row['Country Longitude']], popup=row['Country']).add_to(m)\n",
    "\n",
    "# Add polygon overlays for countries using the loaded GeoJSON data\n",
    "folium.GeoJson(data=geojson_data).add_to(m)\n",
    "\n",
    "# Save and display the map\n",
    "m.save('map.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c45914",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f2663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
